{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 사전 학습된 BERT 모델로 질문에 대한 답변을 제시하는 예제\n",
        "\n",
        "## 사전에 필요한 라이브러리 다운로드"
      ],
      "metadata": {
        "id": "hsNXDbXBr1VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. 사전에 필요한 라이브러리 다운로드\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "sPgiDlGrqMMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoModelForQuestionAnswering:\n",
        "\n",
        "- 사전 학습된 질문-답변 모델을 불러오기 위한 라이브러리\n",
        "- 예: SQuAD(SQuAD 2.0 등) 데이터셋으로 학습된 BERT 모델 사용"
      ],
      "metadata": {
        "id": "s5ageY9QsNwm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vEUtSsZpzZe"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## bert-large-uncased-whole-word-masking-finetuned-squad 모델과 Tokenizer\n",
        "\n",
        "- 사용할 사전 학습된 모델의 이름을 지정\n",
        "  - **`bert-large`**: BERT의 대형 버전으로, 더 큰 크기의 모델(3억 4천만 개의 파라미터)을 사용.\n",
        "  - **`uncased`**: 영어 텍스트에서 대소문자를 구분하지 않음.\n",
        "  - **`whole-word-masking`**: BERT 모델이 사전 학습 중 단어 전체를 마스킹하는 방식.\n",
        "  - **`finetuned-squad`**: SQuAD 데이터셋에 대해 파인튜닝된 질문-답변 모델.\n",
        "\n",
        "- Tokenizer 역할: 입력 데이터 전처리\n",
        "  - 텍스트를 토큰으로 분리(예: `\"Transformers\"` → `['transform', '##ers']`).\n",
        "  - 토큰을 정수 ID로 매핑(예: `['transform', '##ers']` → `[19204, 2900]`)."
      ],
      "metadata": {
        "id": "vaK94fWqtACA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 모델과 토크나이저 로드\n",
        "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "wtGlg3zjp69N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  질문과 컨텍스트 설정"
      ],
      "metadata": {
        "id": "BJ4bXs6-uJGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 질문과 컨텍스트 설정\n",
        "context = \"\"\"\n",
        "BERT (Bidirectional Encoder Representations from Transformers) is a transformer-based machine learning model\n",
        "for natural language processing (NLP) pre-training developed by Dongle(Dongjun & Google). BERT was created and published in 2018\n",
        "by Jacob Devlin and his colleagues from Dongle.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Who developed BERT?\""
      ],
      "metadata": {
        "id": "sXo7fxbPp8wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 입력 토큰화\n",
        "\n",
        "문장을 토큰화하고, 특수 토큰([CLS], [SEP])을 추가한 결과는 다음과 같다.\n",
        "\n",
        "| **토큰**    | **[CLS]** | **who**  | **developed** | **bert**  | **?**    | **[SEP]** |\n",
        "| ----------- | --------- | -------- | ------------- | --------- | -------- | --------- |\n",
        "| **정수 ID** | **101**   | **2040** | **2764**      | **14324** | **1029** | **102**   |\n"
      ],
      "metadata": {
        "id": "RPmJNvbduMEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 입력 토큰화\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "# inputs\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "qnzO881Zp99F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델로 예측"
      ],
      "metadata": {
        "id": "JYN__Kx_wnWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델로 예측\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "DqW58ltCp_FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 예측된 시작과 끝 위치를 가져오기\n",
        "\n",
        "- 확률 관점에서 가장 가능성이 높은 답변을 추출 가능\n",
        "- 확률 기반 접근은 자연어 처리의 모호성과 문맥 의존성을 효과적으로 처리 가능"
      ],
      "metadata": {
        "id": "ywx8a76-wpL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 예측된 시작과 끝 위치를 가져오기\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits\n",
        "\n",
        "start_index = torch.argmax(start_scores)\n",
        "end_index = torch.argmax(end_scores)"
      ],
      "metadata": {
        "id": "LZFgmVIRqAS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 토큰을 문자열로 디코딩하여 답변 생성\n",
        "- Dongle로 정확한 답변을 제시"
      ],
      "metadata": {
        "id": "CKCspGTRw-1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 토큰을 문자열로 디코딩하여 답변 생성\n",
        "answer = tokenizer.decode(inputs[\"input_ids\"][0][start_index : end_index + 1])\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "id": "R9jtma2vqBvK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}